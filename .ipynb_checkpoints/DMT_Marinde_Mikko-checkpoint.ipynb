{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e5fe258b7710d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3331ab427ae55680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data():\n",
    "    \"\"\"\n",
    "    Imports data from the ODI-2025.csv file without modifying it, aside from column names.\n",
    "\n",
    "    :return: The contents of ODI-2025.csv as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    usecols = ['Timestamp',\n",
    "               'What programme are you in?',\n",
    "               'Have you taken a course on machine learning?',\n",
    "               'Have you taken a course on information retrieval?',\n",
    "               'Have you taken a course on statistics?',\n",
    "               'Have you taken a course on databases?',\n",
    "               'What is your gender?',\n",
    "               'I have used ChatGPT to help me with some of my study assignments ',\n",
    "               'When is your birthday (date)?',\n",
    "               'How many students do you estimate there are in the room?',\n",
    "               'What is your stress level (0-100)?',\n",
    "               'How many hours per week do you do sports (in whole hours)? ',\n",
    "               'Give a random number',\n",
    "               'Time you went to bed Yesterday',\n",
    "               'What makes a good day for you (1)?',\n",
    "               'What makes a good day for you (2)?']\n",
    "    names = ['timestamp',\n",
    "             'programme',\n",
    "             'machine_learning',\n",
    "             'information_retrieval',\n",
    "             'statistics',\n",
    "             'databases',\n",
    "             'gender',\n",
    "             'chatgpt',\n",
    "             'birthday',\n",
    "             'student_estimate',\n",
    "             'stress',\n",
    "             'sports',\n",
    "             'random_number',\n",
    "             'bedtime',\n",
    "             'good_day_1',\n",
    "             'good_day_2']\n",
    "\n",
    "    df = pd.read_csv('files/ODI-2025.csv', usecols=usecols, sep=';')\n",
    "    df.columns = names\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_dataframe_to_file(df, filename):\n",
    "    \"\"\"\n",
    "    Saves a pandas dataframe to the file DMT_Data.csv with separator ;.\n",
    "\n",
    "    :param df: Pandas dataframe\n",
    "    \"\"\"\n",
    "    df.to_csv('files/' + filename, index=False, sep=';', decimal='.')\n",
    "\n",
    "\n",
    "\n",
    "def import_data(filename):\n",
    "    return pd.read_csv('files/' + filename, sep=';')\n",
    "    \n",
    "\n",
    "def import_clean_data():\n",
    "    return pd.read_csv('files/DMT_Data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9e6ad6623a278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_string(df, colname):\n",
    "    cleaned_column = df[colname].apply(lambda x: ' '.join(x.split()))\n",
    "    return ' '.join(cleaned_column)\n",
    "\n",
    "\n",
    "def column_wordcloud(filename, column):\n",
    "    data = pd.read_csv('files/' + filename, sep=';')\n",
    "    column_string = column_to_string(data, column)\n",
    "    wordcloud = WordCloud(width=800,\n",
    "                          height=400,\n",
    "                          background_color='white',\n",
    "                          colormap='viridis'\n",
    "                          ).generate(column_string)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f'figures/{column}_wordcloud.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a20f99419faad7",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d48ef12fb7904",
   "metadata": {},
   "source": [
    "### Convert to Standard Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8948c3b7fc471eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ai(programme):\n",
    "    return bool(re.search(r'\\b(ai|artificial|artifical|inteligence|intelligence)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_cs(programme):\n",
    "    return bool(re.search(r'\\b(cs|computer science|comp sci)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_cls(programme):\n",
    "    return bool(re.search(r'\\b(cls|computational science)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_econometrics(programme):\n",
    "    return bool(re.search(r'\\b(econometrics|eor)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_finance(programme):\n",
    "    return bool(re.search(r'\\b(finance|fintech)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_business(programme):\n",
    "    return bool(re.search(r'\\b(business|BA)\\b', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def check_bioinformatics(programme):\n",
    "    return bool(re.search(r'bio', programme, re.IGNORECASE))\n",
    "\n",
    "\n",
    "def clean_programmes(df):\n",
    "    for idx, programme in df['programme'].items():\n",
    "        if check_ai(programme):\n",
    "            df.at[idx, 'programme'] = 'Artificial Intelligence'\n",
    "        elif check_cs(programme):\n",
    "            df.at[idx, 'programme'] = 'Computer Science'\n",
    "        elif check_cls(programme):\n",
    "            df.at[idx, 'programme'] = 'Computational Science'\n",
    "        elif check_econometrics(programme):\n",
    "            df.at[idx, 'programme'] = 'Econometrics'\n",
    "        elif check_finance(programme):\n",
    "            df.at[idx, 'programme'] = 'Finance'\n",
    "        elif check_business(programme):\n",
    "            df.at[idx, 'programme'] = 'Business Analytics'\n",
    "        elif check_bioinformatics(programme):\n",
    "            df.at[idx, 'programme'] = 'Bioinformatics'\n",
    "        else:\n",
    "            df.at[idx, 'programme'] = 'Other'\n",
    "            # print(df.at[idx, 'programme'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e3e84c8a359e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_course_experience(df):\n",
    "    for column in ['machine_learning', 'information_retrieval', 'statistics', 'databases']:\n",
    "        for idx, value in df[column].items():\n",
    "            if value in ['yes', '1', 'mu', 'ja']:\n",
    "                df.at[idx, column] = 'yes'\n",
    "            elif value in ['no', '0', 'sigma', 'nee']:\n",
    "                df.at[idx, column] = 'no'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65638299f2d181a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gender(df):\n",
    "    for idx, value in df['gender'].items():\n",
    "        if value != 'male' and value != 'female':\n",
    "            df.at[idx, 'gender'] = 'other'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfaeacef423e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_birthdays(df):\n",
    "    for idx, value in df['birthday'].items():\n",
    "        value = str(value)\n",
    "        if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', value):\n",
    "            # dd-mm-yyyy\n",
    "            df.at[idx, 'birthday'] = value.replace('-', '/')\n",
    "        elif re.match(r'^\\d{2}-\\d{2}-\\d{2}$', value):\n",
    "            # mm-dd-yy\n",
    "            mm, dd, yy = value.split('-')\n",
    "            century = '20' if int(yy) <= 25 else '19'\n",
    "            formatted_value = f\"{dd}/{mm}/{century}{yy}\"\n",
    "            df.at[idx, 'birthday'] = formatted_value\n",
    "        elif re.match(r'^\\d{8}$', value):\n",
    "            # ddmmyyyy\n",
    "            if float(value[4:]) > 1925:\n",
    "                formatted_value = f\"{value[:2]}/{value[2:4]}/{value[4:]}\"\n",
    "                df.at[idx, 'birthday'] = formatted_value\n",
    "        elif re.match(r'^\\d{2}\\.\\d{2}\\.\\d{4}$', value):\n",
    "            # dd.mm.yyyy\n",
    "            df.at[idx, 'birthday'] = value.replace('.', '/')\n",
    "        elif re.match(r'^\\d{4}\\.\\d{2}\\.\\d{2}$', value):\n",
    "            # yyyy.mm.dd\n",
    "            yyyy, mm, dd = value.split('.')\n",
    "            formatted_value = f\"{dd}/{mm}/{yyyy}\"\n",
    "            df.at[idx, 'birthday'] = formatted_value\n",
    "        elif re.match(r'^\\d{4}-\\d{2}-\\d{2}$', value):\n",
    "            # yyyy-mm-dd\n",
    "            yyyy, mm, dd = value.split('-')\n",
    "            formatted_value = f\"{dd}/{mm}/{yyyy}\"\n",
    "            df.at[idx, 'birthday'] = formatted_value\n",
    "        elif re.match(r'^\\d{2} \\d{2} \\d{4}$', value):\n",
    "            # dd mm yyyy\n",
    "            df.at[idx, 'birthday'] = value.replace(' ', '/')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b56b8589c18dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_numeric(x):\n",
    "    x = str(x)\n",
    "    x = re.sub(r'[^0-9.,E+\\-]', '', x)\n",
    "    if '-' in x[1:]:\n",
    "        x = x.split('-', 1)[0]\n",
    "    if x.count('E') > 1:\n",
    "        x = x.replace('E', '')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e59ebbe80f82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_numeric_in_column(df, column):\n",
    "    df[column] = df[column].apply(\n",
    "        lambda x: remove_non_numeric(x)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41bab3f7bb084b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_student_estimate(df):\n",
    "    df = remove_non_numeric_in_column(df, 'student_estimate')\n",
    "    df['student_estimate'] = df['student_estimate'].replace('', np.nan)\n",
    "    df['student_estimate'] = df['student_estimate'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ceea0a84235a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_stress(df):\n",
    "    df['stress'] = df['stress'].astype(str)\n",
    "    df['stress'] = df['stress'].apply(lambda x: re.sub(',', '.', x))\n",
    "    df = remove_non_numeric_in_column(df, 'stress')\n",
    "    df['stress'] = df['stress'].replace('', np.nan)\n",
    "    df['stress'] = df['stress'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ff35fb75b615fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_sports(df):\n",
    "    df['sports'] = df['sports'].astype(str)\n",
    "    for idx, value in df['sports'].items():\n",
    "        if value == 'zero':\n",
    "            # the one case that had value 'zero'\n",
    "            df.at[idx, 'sports'] = str(0)\n",
    "        elif bool(re.search(r'-', value)):\n",
    "            # range a-b\n",
    "            lower, higher = value.split('-')\n",
    "            df.at[idx, 'sports'] = lower\n",
    "        elif bool(re.search(r'[.,]', value)):\n",
    "            # decimal (question asked for whole hours)\n",
    "            integral, _ = re.split(r'[.,]', value, maxsplit=1)\n",
    "            df.at[idx, 'sports'] = integral\n",
    "    df = remove_non_numeric_in_column(df, 'sports')\n",
    "    df['sports'] = df['sports'].replace('', np.nan)\n",
    "    df['sports'] = df['sports'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade826670612d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert_random_number(df):\n",
    "    df['random_number'] = df['random_number'].astype(str)\n",
    "    # international notation '.' = decimal, ',' = exponent of 10^3\n",
    "    df['random_number'] = df['random_number'].apply(\n",
    "        lambda x: re.sub(r'\\.', '', x) if x.count('.') > 1 else x\n",
    "    )\n",
    "    df['random_number'] = df['random_number'].apply(\n",
    "        lambda x: re.sub(r',', '.', x) if x.count(',') == 1 else x\n",
    "    )\n",
    "    df = remove_non_numeric_in_column(df, 'random_number')\n",
    "    df['random_number'] = df['random_number'].replace('', np.nan)\n",
    "    df['random_number'] = df['random_number'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e91cd82bd72a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_military_time(time_string):\n",
    "    formats = [\n",
    "        \"%H:%M\", \"%Hh%M\", \"%Hu%M\", \"%H.%M\", \"%I.%M\", \"%H-%M\",\n",
    "        \"%H\", \"%I\", \"%H%M\", \"%I%M\", \"%I%p\", \"%H%p\",\n",
    "        \"%H:%M %p\", \"%I:%M %p\", \"%H %p\", \"%I %p\",\n",
    "        \"%H:%M%p\", \"%I:%M%p\", \"%I.%M%p\"\n",
    "    ]\n",
    "    \n",
    "    for format in formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(time_string.strip().lower(), format)\n",
    "            # Round minutes\n",
    "            minute = dt.minute\n",
    "            if minute < 15:\n",
    "                rounded_minute = 0\n",
    "            elif minute < 45:\n",
    "                rounded_minute = 30\n",
    "            else:\n",
    "                dt += timedelta(hours=1)\n",
    "                rounded_minute = 0\n",
    "            dt = dt.replace(minute=rounded_minute, second=0, microsecond=0)\n",
    "            if 9 <= dt.hour <= 12:\n",
    "                dt = dt.replace(hour=(dt.hour + 12) % 24)\n",
    "            return dt.strftime(\"%H:%M\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    print(f\"Could not parse time_string: {time_string}\")\n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bed8c1b4f025cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bedtime(df):\n",
    "    for idx, value in df['bedtime'].items():\n",
    "        df.at[idx, 'bedtime'] = convert_to_military_time(value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98153b673e6f2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save(df):\n",
    "    df.drop(df.tail(1).index,inplace=True)\n",
    "    df = clean_programmes(df)\n",
    "    df = convert_course_experience(df)\n",
    "    df = convert_birthdays(df)\n",
    "    df = clean_and_convert_student_estimate(df)\n",
    "    df = clean_and_convert_stress(df)\n",
    "    df = clean_and_convert_sports(df)\n",
    "    df = clean_and_convert_random_number(df)\n",
    "    df = convert_bedtime(df)\n",
    "    save_dataframe_to_file(df, 'DMT_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15cc76ebef6d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse time_string: Midnight\n",
      "Could not parse time_string: 3 AM x)\n",
      "Could not parse time_string: around midnight\n",
      "Could not parse time_string: 1743502757\n"
     ]
    }
   ],
   "source": [
    "clean_and_save(import_raw_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4e520c6d0fa4d",
   "metadata": {},
   "source": [
    "After data formatting and saving to DMT_Data.csv, some birthdays were manually adjusted to fit the format dd/mm/yyyy, and some bedtimes to hh:mm. Furthermore, rows 174, 240 were removed for being invalid. The result was saved to DMT_Data_Manual.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa17938f046e40",
   "metadata": {},
   "source": [
    "### Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe2861eeeaffe7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(df):\n",
    "    df['birthday'] = pd.to_datetime(df['birthday'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    \n",
    "    df['age'] = df.apply(\n",
    "        lambda row: (row['timestamp'].year - row['birthday'].year) \n",
    "                    - ((row['timestamp'].month, row['timestamp'].day) < \n",
    "                       (row['birthday'].month, row['birthday'].day)),\n",
    "        axis=1\n",
    "    ).astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0757f5cdcb4be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data('DMT_Data_Manual.csv')\n",
    "save_dataframe_to_file(calculate_age(df), 'DMT_Data_Age.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc63ece8718051",
   "metadata": {},
   "source": [
    "### Removing Invalid Data\n",
    "Removal of data based on values outside of a realistic/predetermined range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a54665f3616e3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_ages(df):\n",
    "    df['age'] = df['age'].where((df['age'] >= 16) & (df['age'] <= 80), np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "504cf9c647ce8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_student_estimates(df):\n",
    "    df['student_estimate'] = df['student_estimate'].where((df['student_estimate'] >= 50) & (df['student_estimate'] <= 800), np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbbb9d8443fa8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_stress(df):\n",
    "    df['stress'] = df['stress'].where((df['stress'] >= 0) & (df['stress'] <= 100), np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72b7afdb19f32c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_sports(df):\n",
    "    df['sports'] = df['sports'].where((df['sports'] >= 0) & (df['sports'] <= 40), np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7644c8818dfccd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_bedtimes(df):\n",
    "    pattern = r'^\\d{2}:\\d{2}$'\n",
    "    df['bedtime'] = df['bedtime'].astype(str).apply(\n",
    "        lambda x: x if re.match(pattern, x) else np.nan\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb351e17-f133-4b1c-ace7-74e9f876bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_columns(df):\n",
    "    return df.drop(['birthday', 'random_number', 'good_day_1', 'good_day_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca3d19d2e1219e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_data(df):\n",
    "    df = remove_invalid_ages(df)\n",
    "    df = remove_invalid_student_estimates(df)\n",
    "    df = remove_invalid_stress(df)\n",
    "    df = remove_invalid_sports(df)\n",
    "    df = remove_invalid_bedtimes(df)\n",
    "    df = remove_unused_columns(df)\n",
    "    save_dataframe_to_file(df, 'DMT_Data_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc775396eb488b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_invalid_data(import_data('DMT_Data_Age.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386a5c891d50209",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "Replacing missing values\n",
    "#### Method 1: Replace with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa237c80b42a0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_bedtime(bedtimes):\n",
    "    bedtimes_DT = pd.to_datetime(bedtimes, format='%H:%M', errors='coerce')\n",
    "    bedtimes_seconds = (bedtimes_DT.dt.hour * 3600 + bedtimes_DT.dt.minute * 60)\n",
    "    # Center around midnight s.t. 22:00 becomes -02:00\n",
    "    bedtimes_centered = bedtimes_seconds.apply(lambda s: s - (24 * 3600) if s > (12 * 3600) else s)\n",
    "    median_seconds = bedtimes_centered.median()\n",
    "    median_time = (datetime.min + timedelta(seconds=median_seconds)).strftime('%H:%M')\n",
    "    return median_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55c87708b7b2e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(df):\n",
    "    cols = ['student_estimate', 'stress', 'sports', 'age']\n",
    "    for col in cols:\n",
    "        median = df[col].median()\n",
    "        print('median for col ' + col + ': ' + str(median))\n",
    "        df[col] = df[col].fillna(median)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf4ecefd4dc77066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median for col student_estimate: 350.0\n",
      "median for col stress: 40.0\n",
      "median for col sports: 5.0\n",
      "median for col age: 23.0\n"
     ]
    }
   ],
   "source": [
    "save_dataframe_to_file(impute_median(import_data('DMT_Data_Clean.csv')), 'DMT_Data_Median.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de83fc-13ee-46a9-b0c9-2ecfc0fbfc17",
   "metadata": {},
   "source": [
    "#### Method 2: Class Center Based Median Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04a76ad4-089d-468a-b217-9cfe5b0dbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_missing_by_programme(df):\n",
    "    complete_data = {}\n",
    "    incomplete_data = {}\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    for idx, row in df.iterrows():\n",
    "        class_label = row['programme']\n",
    "        row_numeric = row[numeric_cols]\n",
    "        missing_cols = row_numeric[row_numeric.isnull()].index.tolist()\n",
    "\n",
    "        if len(missing_cols) > 0:\n",
    "            if class_label not in incomplete_data:\n",
    "                incomplete_data[class_label] = {}\n",
    "            incomplete_data[class_label][idx] = row_numeric\n",
    "        else:\n",
    "            if class_label not in complete_data:\n",
    "                complete_data[class_label] = pd.DataFrame(columns=row_numeric.index)\n",
    "            complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
    "    return complete_data, incomplete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b079a6d-c3a9-47f0-ae34-921761a17b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresholds(complete_data):\n",
    "    thresholds = {}\n",
    "    for class_label in complete_data:\n",
    "        class_df = complete_data[class_label]\n",
    "        class_mean = class_df.mean()\n",
    "        euclidean_distances = np.sqrt(((class_df - class_mean) ** 2).sum(axis=1))\n",
    "        thresholds[class_label] = euclidean_distances.median()\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92388fd2-4e54-435a-96d1-9885fddb20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_std(base_distance, missing_cols, row, class_std, class_mean):\n",
    "    min_distance = base_distance\n",
    "    best_col = ''\n",
    "    for col in missing_cols:\n",
    "        row_copy = row.copy()\n",
    "        row_copy[col] -= class_std[col]\n",
    "        euclidean_distance = np.sqrt(((row_copy - class_mean) ** 2).sum())\n",
    "        if euclidean_distance < min_distance:\n",
    "            best_col = col\n",
    "    if best_col != '':\n",
    "        row[best_col] -= class_std[best_col]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f153b44a-62b1-4e69-94e9-5e59490f951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_CCMVI(df):\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "    complete_data, incomplete_data = separate_missing_by_programme(df)\n",
    "    thresholds = find_thresholds(complete_data)\n",
    "    for class_label, incomplete_dict in incomplete_data.items():\n",
    "        class_df = complete_data[class_label]\n",
    "        class_mean = class_df.mean()\n",
    "        class_std = class_df.std()\n",
    "        for idx, row in incomplete_dict.items():\n",
    "            missing_cols = row[row.isnull()].index.tolist()\n",
    "            for col in missing_cols:\n",
    "                row[col] = class_mean[col]\n",
    "            euclidean_distance = np.sqrt(((row - class_mean) ** 2).sum())\n",
    "            if euclidean_distance > thresholds[class_label]:\n",
    "                row = select_best_std(euclidean_distance, missing_cols, row, class_std, class_mean)\n",
    "            incomplete_data[class_label][idx] = row.astype(float)\n",
    "    for class_label, incomplete_dict in incomplete_data.items():\n",
    "        for idx, row in incomplete_dict.items():\n",
    "            df.loc[idx, row.index] = row.astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c57ddf9-8578-4d97-a5e2-c0f21f2589c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n",
      "/var/folders/3v/6kq_73ns7j57377v07xc6t_40000gn/T/ipykernel_27599/4238402064.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  complete_data[class_label] = pd.concat([complete_data[class_label], pd.DataFrame([row_numeric])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = import_data('DMT_Data_Clean.csv')\n",
    "save_dataframe_to_file(impute_CCMVI(df), 'DMT_Data_CCMVI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1778f0934528e",
   "metadata": {},
   "source": [
    "### Transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58244ef51edf47c7",
   "metadata": {},
   "source": [
    "#### Numerical Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dda40a9f7116bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, columns):\n",
    "    return pd.get_dummies(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b115e61795f1ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, columns):\n",
    "    for col in columns:\n",
    "        min_value = df[col].min()\n",
    "        max_value = df[col].max()\n",
    "        print(f'Min value for {col}: {min_value}')\n",
    "        print(f'Max value for {col}: {max_value}')\n",
    "        df[col] = (df[col]-min_value)/(max_value-min_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "883c3931e40b200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bedtime_to_mins_past_three(df):\n",
    "    bedtimes = pd.to_datetime(df['bedtime'], format='%H:%M').dt.time\n",
    "    bedtimes_mins = bedtimes.apply(lambda t: t.hour * 60 + t.minute)\n",
    "    df['bedtime'] = (bedtimes_mins - 900) % 1440\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f0fd80f2a8ff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerically(df):\n",
    "    categorical = ['programme', 'machine_learning', 'information_retrieval', 'statistics', 'databases', 'gender', 'chatgpt']\n",
    "    numerical = ['stress', 'student_estimate', 'sports', 'bedtime', 'age']\n",
    "    df = bedtime_to_mins_past_three(df)\n",
    "    df = one_hot_encode(df, categorical)\n",
    "    df = normalize(df, numerical)\n",
    "    save_dataframe_to_file(df, 'DMT_Data_Numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "276ed93336b81a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value for stress: 0.0\n",
      "Max value for stress: 100.0\n",
      "Min value for student_estimate: 80.0\n",
      "Max value for student_estimate: 600.0\n",
      "Min value for sports: 0.0\n",
      "Max value for sports: 23.0\n",
      "Min value for bedtime: 240\n",
      "Max value for bedtime: 1320\n",
      "Min value for age: 19.0\n",
      "Max value for age: 42.0\n"
     ]
    }
   ],
   "source": [
    "df = import_data('DMT_Data_CCMVI.csv')\n",
    "encode_numerically(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f85c2425ee982",
   "metadata": {},
   "source": [
    "#### Categorical Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15f42fec84d12da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_programme(df):\n",
    "    programmes = df['programme']\n",
    "    programme_mapping = {program: idx for idx, program in enumerate(programmes.unique())}\n",
    "    # make 'Other' the last entry\n",
    "    last_integer = len(programme_mapping) - 1\n",
    "    last_programme = [programme for programme, value in programme_mapping.items() if value == last_integer][0]\n",
    "    other_integer = programme_mapping['Other']\n",
    "    programme_mapping['Other'] = last_integer\n",
    "    programme_mapping[last_programme] = other_integer\n",
    "    df['programme'] = df['programme'].map(programme_mapping)\n",
    "    print(\"Programmes mapped:\", programme_mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82c47c2d8783349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_student_estimate(df):\n",
    "    # low = 0-300, Medium = 301-450, High = 451+\n",
    "    bins = [float('-inf'), 300, 450, float('inf')]\n",
    "    labels = ['low', 'medium', 'high']\n",
    "    df['student_estimate'] = pd.cut(df['student_estimate'], bins=bins, labels=labels, right=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51257c748a4c4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stress(df):\n",
    "    # Low = 0-33, Medium = 34-66, High = 67-100\n",
    "    # lower_third = df['stress'].quantile(0.33)\n",
    "    # upper_two_third = df['stress'].quantile(0.66)\n",
    "    # bins = [float('-inf'), lower_third, upper_two_third, 100]\n",
    "    bins = [float('-inf'), 33, 66, 100]\n",
    "    labels = ['low', 'medium', 'high']\n",
    "    df['stress'] = pd.cut(df['stress'], bins=bins, labels=labels, right=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae6566b216da9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sports(df):\n",
    "    # Low = 0-2, Medium = 3-6, High = 7+\n",
    "    bins = [float('-inf'), 2, 6, float('inf')]\n",
    "    labels = ['low', 'medium', 'high']\n",
    "    df['sports'] = pd.cut(df['sports'], bins=bins, labels=labels, right=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "faefbdd3e91a24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_bedtime(df):\n",
    "    df = bedtime_to_mins_past_three(df)\n",
    "    # Early = before 10pm, Middle = 10:01pm-1am, Late = past 1:01am\n",
    "    bins = [float('-inf'), 420, 600, float('inf')]\n",
    "    labels = ['early', 'middle', 'late']\n",
    "    df['bedtime'] = pd.cut(df['bedtime'], bins=bins, labels=labels, right=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e22431c52acc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_age(df):\n",
    "    # Young = 0-21, Middle = 22-25, Old = 26+\n",
    "    bins = [float('-inf'), 21, 25, float('inf')]\n",
    "    labels = ['young', 'middle', 'old']\n",
    "    df['age'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66cef8b56e0f93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_classifiers(df):\n",
    "    categorical = ['programme', 'machine_learning', 'information_retrieval', 'statistics', 'databases', 'gender', 'chatgpt']\n",
    "    numerical = ['student_estimate', 'sports', 'bedtime', 'age']\n",
    "    df = bedtime_to_mins_past_three(df)\n",
    "    df = one_hot_encode(df, categorical)\n",
    "    # make stress categorical for classifiers\n",
    "    df = encode_stress(df)\n",
    "    df = normalize(df, numerical)\n",
    "    save_dataframe_to_file(df, 'DMT_Data_Classifiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cad7febfe810b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value for student_estimate: 80.0\n",
      "Max value for student_estimate: 600.0\n",
      "Min value for sports: 0.0\n",
      "Max value for sports: 23.0\n",
      "Min value for bedtime: 240\n",
      "Max value for bedtime: 1320\n",
      "Min value for age: 19.0\n",
      "Max value for age: 42.0\n"
     ]
    }
   ],
   "source": [
    "df = import_data('DMT_Data_CCMVI.csv')\n",
    "encode_classifiers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250774a34ac32df7",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aaa3c80dc6ab580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bedtimes(ax, df, title):\n",
    "    bedtimes_DT = pd.to_datetime(df['bedtime'], format='%H:%M', errors='coerce')\n",
    "    bedtimes_seconds = bedtimes_DT.dt.hour * 3600 + bedtimes_DT.dt.minute * 60\n",
    "    half_day = 43200\n",
    "    centered_bedtimes = bedtimes_seconds.apply(lambda x: x - 86400 if x > half_day else x)\n",
    "    sorted_bedtimes = np.sort(centered_bedtimes)\n",
    "    counts = pd.Series(sorted_bedtimes).value_counts().sort_index()\n",
    "    if counts.sum() > 0:\n",
    "        counts.plot(kind='bar', color='skyblue', edgecolor='black', ax=ax)\n",
    "    else:\n",
    "        print(f\"No valid data to plot for {title}\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"bedtime\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    tick_labels = [str(datetime.utcfromtimestamp(x).strftime('%H:%M')) for x in counts.index]\n",
    "    ax.set_xticks(np.arange(len(tick_labels)))\n",
    "    ax.set_xticklabels(tick_labels, rotation=90)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0d0ea00-2575-421b-8331-c29e335c3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(ax, df, column, title):\n",
    "    # Plot the histogram\n",
    "    print(df[column])\n",
    "    df[column].plot(kind='hist', bins=10, color='skyblue', edgecolor='black', alpha=0.7, ax=ax)\n",
    "    \n",
    "    # Access the patches (bars) of the histogram to get the counts of each bin\n",
    "    counts, edges, patches = ax.hist(df[column], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Print the sum of the counts (total number of elements)\n",
    "    total_counts = counts.sum()\n",
    "    print(f\"Sum of counts in all bins for {column}: {total_counts}\")\n",
    "    \n",
    "    # Plot labels and grid\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4c6a7f3-16d6-467a-a546-90b472852b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imputations():\n",
    "    cols = ['student_estimate', 'stress', 'sports', 'bedtime', 'age']\n",
    "    \n",
    "    # Import the dataframes\n",
    "    df_ccmvi = import_data('DMT_Data_CCMVI.csv')\n",
    "    df_median = import_data('DMT_Data_Median.csv')\n",
    "    df_na = import_data('DMT_Data_Clean.csv')\n",
    "    \n",
    "    for col in cols:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        title = f'Histogram of {col} for dataset '\n",
    "        if col == 'bedtime':\n",
    "            plot_bedtimes(axes[0], df_ccmvi, title + 'CCMVI')\n",
    "            plot_bedtimes(axes[1], df_median, title + 'Median')\n",
    "            plot_bedtimes(axes[2], df_na, title + 'Clean')\n",
    "        else:\n",
    "            plot_dist(axes[0], df_ccmvi, col, title + 'CCMVI')\n",
    "            plot_dist(axes[1], df_median, col, title + 'Median')\n",
    "            plot_dist(axes[2], df_na, col, title + 'Clean')\n",
    "        \n",
    "        # Save the figure to a file\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figures/{col}_imputation.png')\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "def plot_value_counts(ax, df, column, title):\n",
    "    counts = df[column].value_counts(dropna=False).head(10)\n",
    "    counts.plot(kind='bar', ax=ax)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce7b0d-e4c7-4ab1-a9ec-836d5655bf29",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61074f5f-eb37-4262-a386-9a58f14e0c9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2025-04-01 12:17:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier_df \u001b[38;5;241m=\u001b[39m import_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDMT_Data_Classifiers.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m numerical_df \u001b[38;5;241m=\u001b[39m import_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDMT_Data_Numerical.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m pos_correlations \u001b[38;5;241m=\u001b[39m numerical_df\u001b[38;5;241m.\u001b[39mcorr()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnlargest(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)\n\u001b[1;32m      4\u001b[0m pos_correlations\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstress\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pos_correlations)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2025-04-01 12:17:00'"
     ]
    }
   ],
   "source": [
    "classifier_df = import_data('DMT_Data_Classifiers.csv')\n",
    "numerical_df = import_data('DMT_Data_Numerical.csv')\n",
    "pos_correlations = numerical_df.corr()['stress'].nlargest(n=11)\n",
    "pos_correlations.pop('stress')\n",
    "print(pos_correlations)\n",
    "neg_correlations = numerical_df.corr()['stress'].nsmallest(10)\n",
    "print(neg_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23294823-7f5c-4dca-91b2-fcf948760c1e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc59dddc-6ba3-48ca-99de-3f074b2c5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X, y, max_iter=30, stop_early=True):\n",
    "    average_acc = []\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    max_acc = 0\n",
    "    worse_accs = 0\n",
    "    d = 1\n",
    "    while d <= max_iter:\n",
    "        print(d)\n",
    "        scores = []\n",
    "        for j in range(300):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=j)\n",
    "            clf = tree.DecisionTreeClassifier(max_depth = d)\n",
    "            # clf = RandomForestClassifier(max_depth=d, n_estimators=50, random_state=j)\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            scores.append(accuracy_score(y_test, y_pred))\n",
    "        mean_acc = np.mean(scores)\n",
    "        ci = 1.96 * np.std(scores)/np.sqrt(len(scores))\n",
    "        average_acc.append(mean_acc)\n",
    "        lower_bounds.append(mean_acc - ci)\n",
    "        upper_bounds.append(mean_acc + ci)\n",
    "        if mean_acc > max_acc:\n",
    "            worse_accs = 0\n",
    "            max_acc = mean_acc\n",
    "            print(f'max acc: {max_acc}, mean acc: {mean_acc}')\n",
    "        elif stop_early:\n",
    "            # stop increasing depth if the accuracy has been worse than the best accuracy for 3 iterations\n",
    "            worse_accs += 1\n",
    "            print(f'max acc: {max_acc}, mean acc: {mean_acc}')\n",
    "            if worse_accs == 3:\n",
    "                print(f'Best depth: {d-3}')\n",
    "                break\n",
    "            elif d == max_iter:\n",
    "                print(f'Best depth: {d}')\n",
    "        d += 1\n",
    "    return lower_bounds,upper_bounds, average_acc, max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "319ddd6e-7f2a-4abe-ad01-24a083f9bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, pos_correlations, neg_correlations):\n",
    "    y = df['stress']\n",
    "    predictors = []\n",
    "    num_predictors = []\n",
    "    max_accs = []\n",
    "    best_acc = 0\n",
    "    i = 0\n",
    "    while i < len(pos_correlations.index):\n",
    "        col = pos_correlations.index[i]\n",
    "        predictors.append(col)\n",
    "        num_predictors.append(len(predictors))\n",
    "        X = df[predictors]\n",
    "        lower_bounds, upper_bounds, accuracies, max_acc = k_fold(X, y)\n",
    "        max_accs.append(max_acc)\n",
    "        print(f'Attributes: {predictors}, Accuracy: {max_acc}')\n",
    "        col = neg_correlations.index[i]\n",
    "        predictors.append(col)\n",
    "        num_predictors.append(len(predictors))\n",
    "        X = df[predictors]\n",
    "        lower_bounds, upper_bounds, accuracies, max_acc = k_fold(X, y)\n",
    "        max_accs.append(max_acc)\n",
    "        print(f'Attributes: {predictors}, Accuracy: {max_acc}')\n",
    "        i += 1\n",
    "    return num_predictors, max_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fcd7e644-34d6-4ad6-82f0-6aad4dccbe66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_predictors, max_accs \u001b[38;5;241m=\u001b[39m feature_selection(classifier_df, pos_correlations, neg_correlations)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(num_predictors, max_accs, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax average accuracy vs. number of features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos_correlations' is not defined"
     ]
    }
   ],
   "source": [
    "num_predictors, max_accs = feature_selection(classifier_df, pos_correlations, neg_correlations)\n",
    "plt.plot(num_predictors, max_accs, marker='o')\n",
    "plt.title(\"Max average accuracy vs. number of features\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Max average accuracy\")\n",
    "plt.locator_params(axis='x', nbins=11)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee4566-7115-4241-835f-183d63266416",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_predictors, max_accs = feature_selection(classifier_df, pos_correlations, neg_correlations)\n",
    "plt.plot(num_predictors, max_accs, marker='o')\n",
    "plt.title(\"Max average accuracy vs. number of features\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Max average accuracy\")\n",
    "plt.locator_params(axis='x', nbins=11)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2eb9b-0fb9-4f8d-98dc-24a58314e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classifier_df[['bedtime', 'sports', 'gender_other', 'gender_male', 'information_retrieval_unknown', 'chatgpt_yes',\n",
    "                   'chatgpt_not willing to say', 'information_retrieval_yes']]\n",
    "y = classifier_df['stress']\n",
    "lower_bounds, upper_bounds, accuracies, max_acc = k_fold(X, y, stop_early=False)\n",
    "\n",
    "plt.fill_between(range(1, len(accuracies)+1), lower_bounds, upper_bounds, color='gray', alpha=0.3, label='95% Confidence Interval')\n",
    "plt.plot(range(1, len(accuracies)+1), accuracies, marker='o')\n",
    "plt.title(\"Average accuracy vs. max_depth\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Average accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445c0b7-2d7e-4119-a3b0-71037ae31a64",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ffb24-aa78-4dc7-ae11-094254aab345",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['gender_male', 'sports', 'bedtime', 'chatgpt_yes', 'chatgpt_not willing to say', 'gender_other',\n",
    "       'information_retrieval_yes']\n",
    "target = 'stress'\n",
    "\n",
    "def naive_bayes(df, features, target):\n",
    "    average_accuracy = []\n",
    "    for i in range(200):\n",
    "        X = df[features]\n",
    "        y = df[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train, y_train)\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        average_accuracy.append(acc)\n",
    "    return average_accuracy, y_test, y_pred\n",
    "\n",
    "def feature_selection(df, pos_correlations, neg_correlations):\n",
    "    predictors = []\n",
    "    num_predictors = []\n",
    "    max_accs = []\n",
    "    best_acc = 0\n",
    "    i = 0\n",
    "    while i < len(pos_correlations.index):\n",
    "        col = pos_correlations.index[i]\n",
    "        predictors.append(col)\n",
    "        num_predictors.append(len(predictors))\n",
    "        average_accuracy, _, _ = naive_bayes(df, predictors, 'stress')\n",
    "        max_accs.append(np.mean(average_accuracy))\n",
    "        print(f'Attributes: {predictors}, Accuracy: {np.mean(average_accuracy)}')\n",
    "        col = neg_correlations.index[i]\n",
    "        predictors.append(col)\n",
    "        num_predictors.append(len(predictors))\n",
    "        average_accuracy, _, _ = naive_bayes(df, predictors, 'stress')\n",
    "        max_accs.append(np.mean(average_accuracy))\n",
    "        print(f'Attributes: {predictors}, Accuracy: {np.mean(average_accuracy)}')\n",
    "        i += 1\n",
    "    return num_predictors, max_accs\n",
    "\n",
    "num_predictors, max_accs = feature_selection(classifier_df, pos_correlations, neg_correlations)\n",
    "plt.plot(num_predictors, max_accs, marker='o')\n",
    "plt.title(\"Max average accuracy vs. number of features\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Max average accuracy\")\n",
    "plt.locator_params(axis='x', nbins=11)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e8ec1-8820-4b9c-b1f0-50d4a2008687",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bedtime', 'sports', 'gender_other', 'gender_male', 'information_retrieval_unknown', 'chatgpt_yes',\n",
    "            'chatgpt_not willing to say', 'information_retrieval_yes', 'gender_female', 'machine_learning_yes', 'machine_learning_no']\n",
    "target = 'stress'\n",
    "average_accuracy, y_test, y_pred = naive_bayes(classifier_df, features, 'stress')\n",
    "mean_accuracy = np.mean(average_accuracy)\n",
    "print(mean_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca30d4-461b-462e-9ea8-ed5df9c9a26c",
   "metadata": {},
   "source": [
    "## Notes Classifier Feature Selection\n",
    "de features zijn gekozen door om de beurt de hoogste en laagste correlations met stress toe te voegen en de classifiers te runnen, en de feature set met de hoogste accuracy te kiezen. voor random forest geldt dat daarbij de optimale depth is inbegrepen (vandaar max average accuracy, iedere depth heeft een average accuracy en daarvan neemt hij de depth met de max)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
